{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f775cee-232d-4982-bdc4-8bb215a69704",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"><h1><center>Downloading NOAA Precipitation for a Watershed </center></h1></span>\n",
    "<center>Prepared by <br>\n",
    "    <b>Jibin Joseph and Venkatesh Merwade</b><br> \n",
    "Lyles School of Civil Engineering, Purdue University<br>\n",
    "joseph57@purdue.edu, vmerwade@purdue.edu<br>\n",
    "<b><br>\n",
    "    FAIR Science in Water Resources</b><br></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128465ec-e1f0-4a87-a3d5-b75cb2a42a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynhd import NLDI\n",
    "import os\n",
    "#from pygeohydro import NWIS\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f9b90f-8020-4f97-8bc2-b66a6c6a07ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## USGS Site Number\n",
    "site_id='03335000'\n",
    "\n",
    "# Date range for the precipitation data\n",
    "start_date = '2024-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "watershed=NLDI().get_basins(site_id,fsource='nwissite')\n",
    "extents_basin=watershed.total_bounds\n",
    "print(extents_basin)\n",
    "## Adding site_id to geodataframe\n",
    "watershed[\"site_id\"]=site_id\n",
    "\n",
    "## Adding other details\n",
    "#nwis = NWIS()\n",
    "#site_info = nwis.get_info({\"site\": site_id}, expanded=True)\n",
    "\n",
    "\n",
    "#watershed[\"site_nm\"] = site_info[\"station_nm\"].iloc[0]\n",
    "#watershed[\"site_lon\"] = site_info[\"dec_long_va\"].iloc[0]  \n",
    "#watershed[\"site_lat\"] = site_info[\"dec_lat_va\"].iloc[0]\n",
    "#watershed[\"dr_ar_sqmi\"]=site_info[\"drain_area_va\"].iloc[0]\n",
    "#watershed[\"hcdn_2009\"]=site_info[\"hcdn_2009\"].iloc[0]\n",
    "\n",
    "print(watershed.head())\n",
    "print(watershed.columns)\n",
    "\n",
    "watershed.plot()\n",
    "\n",
    "# Output folder for CSVs\n",
    "folder_output = f'data_{site_id}'\n",
    "os.makedirs(folder_output, exist_ok=True)\n",
    "shapefile_fileloc_filename=f\"./{folder_output}/shape_{site_id}.shp\"\n",
    "watershed.to_file(filename=shapefile_fileloc_filename,\n",
    "                 driver=\"ESRI Shapefile\",\n",
    "                 mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3289144-59e4-49b1-a74a-9d4899701f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centroids for each geometry\n",
    "watershed['centroid'] = watershed.geometry.centroid\n",
    "\n",
    "# Show result\n",
    "print(watershed[['geometry', 'centroid']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a57b11-3b16-4cbc-85dc-fd2c95a924ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOAA API token (get yours here: https://www.ncdc.noaa.gov/cdo-web/token)\n",
    "API_TOKEN = 'BzJUVDNQCXcethBKDLveceOBxuaTHfxq'\n",
    "\n",
    "# Define bounding box (minlon, minlat, maxlon, maxlat)\n",
    "#bbox = [-125, 30, -65, 50]  # Example: USA lower 48 states\n",
    "bbox = extents_basin\n",
    "\n",
    "# Define request headers\n",
    "headers = {'token': API_TOKEN}\n",
    "\n",
    "# Base URL for NOAA NCEI API stations endpoint\n",
    "base_url = 'https://www.ncei.noaa.gov/cdo-web/api/v2/stations'\n",
    "\n",
    "# Parameters for the request\n",
    "params = {\n",
    "    'datasetid': 'GHCND',         # Global Historical Climatology Network - Daily\n",
    "    'extent': f'{bbox[1]},{bbox[0]},{bbox[3]},{bbox[2]}',  # lat1, lon1, lat2, lon2\n",
    "    'limit': 1000,                # Max records per request\n",
    "    'offset': 1,                  # Start offset\n",
    "}\n",
    "\n",
    "all_stations = []\n",
    "page = 1\n",
    "\n",
    "while True:\n",
    "    print(f'Fetching page {page} with offset {params[\"offset\"]}...')\n",
    "\n",
    "    response = requests.get(base_url, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f'Error: {response.status_code} - {response.text}')\n",
    "        break\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    # Check if there are results\n",
    "    if 'results' not in data or not data['results']:\n",
    "        print('No more stations to fetch.')\n",
    "        break\n",
    "\n",
    "    all_stations.extend(data['results'])\n",
    "\n",
    "    # Pagination: increase offset by limit\n",
    "    params['offset'] += params['limit']\n",
    "    page += 1\n",
    "\n",
    "    # NOAA rate limits: be kind\n",
    "    time.sleep(1)\n",
    "\n",
    "# Convert results to pandas DataFrame\n",
    "df = pd.DataFrame(all_stations)\n",
    "\n",
    "# Select desired columns (if they exist)\n",
    "selected_columns = ['id', 'name', 'latitude', 'longitude', 'elevation', 'mindate', 'maxdate']\n",
    "df_selected = df[selected_columns].copy()\n",
    "\n",
    "# Rename columns if you want\n",
    "df_selected.rename(columns={\n",
    "    'id': 'Station ID',\n",
    "    'latitude': 'Station_Lat',\n",
    "    'longitude': 'Station_Lon',\n",
    "    'mindate': 'Start Date',\n",
    "    'maxdate': 'End Date',\n",
    "    'elevation': 'Elevation'\n",
    "}, inplace=True)\n",
    "\n",
    "# Display and save\n",
    "print(df_selected.head())\n",
    "\n",
    "df_selected.to_csv(f\"./{folder_output}/noaa_all_stations.csv\", index=False)\n",
    "\n",
    "print(f'Download complete: {len(df_selected)} stations saved to noaa_all_stations.csv in {folder_output} folder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c355cfc-aa00-4322-8a16-4d73c9390d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "# Convert to pandas DataFrame first\n",
    "#df = pd.DataFrame(all_stations)\n",
    "\n",
    "# Create a geometry column from Station_Lon and Station_Lat\n",
    "geometry = [Point(xy) for xy in zip(df_selected['Station_Lon'], df_selected['Station_Lat'])]\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf_all = gpd.GeoDataFrame(df_selected, geometry=geometry)\n",
    "\n",
    "# Set a CRS (Coordinate Reference System), assuming WGS84 (EPSG:4326)\n",
    "gdf_all.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# Show the GeoDataFrame\n",
    "print(len(gdf_all))\n",
    "print(gdf_all.head())\n",
    "\n",
    "\n",
    "\n",
    "df_active=df_selected[df_selected['End Date']>=end_date]\n",
    "df_active.to_csv(f\"./{folder_output}/noaa_active_stations.csv\", index=False)\n",
    "# Create a geometry column from Station_Lon and Station_Lat\n",
    "geometry = [Point(xy) for xy in zip(df_active['Station_Lon'], df_active['Station_Lat'])]\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf_active = gpd.GeoDataFrame(df_active, geometry=geometry)\n",
    "\n",
    "# Set a CRS (Coordinate Reference System), assuming WGS84 (EPSG:4326)\n",
    "gdf_active.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# Show the GeoDataFrame\n",
    "print(len(gdf_active))\n",
    "print(gdf_active.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e15b13-30eb-49a8-aa9d-17bf432d1c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Check CRS consistency\n",
    "print(\"Watershed CRS:\", watershed.crs)\n",
    "print(\"Stations CRS:\", gdf_all.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09210c26-9ecb-4cbd-ae1c-aafde278e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the watershed polygons\n",
    "watershed.plot(ax=ax, color='lightblue', edgecolor='blue', alpha=0.5, linewidth=1)\n",
    "\n",
    "# Plot the stations as points\n",
    "gdf_all.plot(ax=ax, color='red', markersize=50, marker='o', label=f'NOAA All {len(gdf_all)} Sites ',alpha=0.25)\n",
    "gdf_active.plot(ax=ax, color='green', markersize=40, marker='x', label=f'NOAA Active {len(gdf_active)} Sites',alpha=1)\n",
    "\n",
    "# Add titles and legend\n",
    "ax.set_title(f\"Watershed and NOAA Precipitation Sites\\n(USGS {site_id})\")#: {site_info['station_nm'].iloc[0]}\\nDrainage Area: {round(site_info['drain_area_va'].iloc[0],2)} sq. mi.)\")\n",
    "ax.legend()\n",
    "# Save the figure as a PNG file\n",
    "plt.savefig(f\"./{folder_output}/{site_id}_plot_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a954ce06-78d3-43b6-8807-8bb46788799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request headers\n",
    "headers = {'token': API_TOKEN}\n",
    "# Base URL for data endpoint\n",
    "base_url = 'https://www.ncei.noaa.gov/cdo-web/api/v2/data'\n",
    "\n",
    "# Dataset and datatype\n",
    "datasetid = 'GHCND'  # Global Historical Climatology Network - Daily\n",
    "datatypeid = 'PRCP'  # Precipitation\n",
    "\n",
    "print(len(df_selected))\n",
    "#print((stations_df.head()))\n",
    "\n",
    "print(len(df_active))\n",
    "print((df_active.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b803f9-71d3-4984-bf0b-c242a2342a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output folder for CSVs\n",
    "output_folder = 'station_precip_data'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to sanitize filename\n",
    "def sanitize_filename(name):\n",
    "    return re.sub(r'[^\\w\\-_\\. ]', '_', name)\n",
    "\n",
    "# Loop through each station\n",
    "for index, row in df_active.iterrows():\n",
    "    station_id = row['Station ID']\n",
    "    print(f\"\\nDownloading PRCP data for station {station_id} ({index + 1}/{len(df_active)})\")\n",
    "\n",
    "    # Prepare parameters for each station\n",
    "    params = {\n",
    "        'datasetid': datasetid,\n",
    "        'datatypeid': datatypeid,\n",
    "        'stationid': station_id,\n",
    "        'startdate': start_date,\n",
    "        'enddate': end_date,\n",
    "        'limit': 1000,\n",
    "        'offset': 1,\n",
    "        'units': 'standard'  # or 'metric'\n",
    "    }\n",
    "\n",
    "    station_data = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        print(f\"Fetching page {page} for {station_id} with offset {params['offset']}...\")\n",
    "\n",
    "        response = requests.get(base_url, headers=headers, params=params)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error for station {station_id}: {response.status_code} - {response.text}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        if 'results' not in data or not data['results']:\n",
    "            print(f\"No more data for station {station_id}.\")\n",
    "            break\n",
    "\n",
    "        station_data.extend(data['results'])\n",
    "\n",
    "        # Pagination: increase offset by limit\n",
    "        params['offset'] += params['limit']\n",
    "        page += 1\n",
    "\n",
    "        # Respect NOAA rate limits\n",
    "        time.sleep(2)\n",
    "\n",
    "    if station_data:\n",
    "        # Convert to DataFrame\n",
    "        station_df = pd.DataFrame(station_data)\n",
    "        station_df['Station ID'] = station_id  # Add station ID to each row\n",
    "\n",
    "        # Clean station ID for filename (remove colons, slashes, etc.)\n",
    "        clean_station_id = sanitize_filename(station_id)\n",
    "\n",
    "        # Build file path\n",
    "        output_file = f\"./{folder_output}/{clean_station_id}.csv\"\n",
    "\n",
    "        # Save to CSV\n",
    "        station_df.to_csv(output_file, index=False)\n",
    "        print(f\"Saved {len(station_df)} records to {output_file}\")\n",
    "    else:\n",
    "        print(f\"No precipitation data found for station {station_id}.\")\n",
    "\n",
    "print(\"\\nDownload complete for all stations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e7b6e-176e-4dd9-be56-422c7d2d2513",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_total=[]\n",
    "\n",
    "for index, row in df_active.iterrows():\n",
    "    station_id = row['Station ID']\n",
    "    # Clean station ID for filename (remove colons, slashes, etc.)\n",
    "    clean_station_id = sanitize_filename(station_id)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(f\"/glade/u/home/jjoseph/prec_noaa_dataaccess/{folder_output}/{clean_station_id}.csv\")\n",
    "\n",
    "    \n",
    "        # Convert 'date' to datetime\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "        # Extract the year\n",
    "        df['year'] = df['date'].dt.year\n",
    "    \n",
    "        # Inspect data\n",
    "        #print(df.head())\n",
    "\n",
    "        # Group by station and year, sum the precipitation values\n",
    "        annual_precip = df.groupby(['Station ID', 'year'])['value'].sum().reset_index()\n",
    "        \n",
    "        # Rename columns for clarity\n",
    "        annual_precip.columns = ['Station ID', 'Year', 'Annual_Total_Precip']\n",
    "        \n",
    "        # Display result\n",
    "        print(annual_precip)\n",
    "\n",
    "    except Exception as e:\n",
    "            #print(f\"Error processing {station_id}: {e}\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb7214-3963-49e5-a131-2c70575f1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd6e53-718f-4f52-aa5c-c40e618118c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r data_03335000.zip data_03335000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct-fair",
   "language": "python",
   "name": "ct-fair"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
